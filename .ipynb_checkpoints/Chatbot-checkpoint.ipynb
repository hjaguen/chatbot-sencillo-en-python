{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot informativo implementado al 100% en Python\n",
    "\n",
    "### Es un ejemplo sencillo de chatbot que implementa el corpus en un archivo '.txt' y que emplea las librerías nltk y scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El chatbot informa a los usuarios acerca de las normas de un crucero. Es un ejemplo básico, pero que bien sirve de ejemplo de uso de lematización y búsqueda de coincidencias entre las preguntas de usuario y las diferentes respuestas posibles mediante el modelo \"cosine_similarity\"\n",
    "\n",
    "#### Resumen técnico.\n",
    "\n",
    "##### 1.- En una variable de texto se almacena el corpus (diferentes respuestas posibles al usuario).\n",
    "##### 2.- Cuando el usuario plantea una pregunta, se agrega -temporalmente- al final de la lista de respuestas. A todo este contenido se le eliminan signos de puntuación, se tokeniza, lematiza y se extraen sus caracterísaticas -mediante TfidfVectorizer de sklearn-. A partir de ellas y empleando un modelo del tipo \"cosine_similarity\" se buscan las respuestas más coincidentes con la pregunta del usuario, se elige la que mayor grado de coincidentcia muestra y se responde con ella.\n",
    "##### 3.- Adicionalmente se ha incluido un pequeño módulo de saludo inicial, que aleatoriamente elige una respuesta entre varias posibles.\n",
    "\n",
    "\n",
    "#### Próximamente subiré un sistema similar pero del tipo \"voice bot\", empleando para ello librerías de reconocimiento y síntesis de voz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "#nltk.download('punkt') # Instalar módulo punkt si no está ya instalado (solo ejecutar la primera vez)\n",
    "#nltk.download('wordnet') # Instalar módulo wordnet si no está ya instalado (solo ejecutar la primera vez)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1 Carga del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el corpus estructurado\n",
    "with open('/home/mauricio/repos/source/chatbot/data.json', 'r') as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "# Inicializar la variable 'raw' con el contenido del corpus\n",
    "raw = \" \".join([item['question'] + \" \" + item['answer'] for item in corpus['faq']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Definición de funciones y variables de apoyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=raw.lower() # Convertimos todo el texto a minúsculas, para evitar deficiencias en la extracción de características\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(raw) # Convierte el corpus a una lista de sentencias\n",
    "word_tokens = nltk.word_tokenize(raw) # Convierte el corpus a una lista de palabras\n",
    "\n",
    "lemmer = nltk.stem.WordNetLemmatizer() # Instanciamos el lematizador, con el que convertir las palabras  a sus raíces contextuales\n",
    "\n",
    "#LemTokens es una función que lematiza todos los tokens que se le pasan como parámetro\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# remove_punct es un diccionario del tipo (0signo de puntuación', None), que se emplea en la función\n",
    "# LemNormalize para sustituir los signos de puntuación por \"nada\" es decir, eliminarlos.\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "# Dado un texto como parámetro, elimina los signos de puntuación, lo convierte a minúsculas,\n",
    "# lo tokeniza -por palabras- y finalmente lo lematiza\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "# Inicializar el corrector ortográfico\n",
    "spell = SpellChecker(language='es')\n",
    "\n",
    "def corregir_entrada(entrada):\n",
    "    \"\"\"\n",
    "    Corrige faltas ortográficas en una entrada de texto.\n",
    "    Si no se encuentra una corrección, se mantiene la palabra original.\n",
    "    \"\"\"\n",
    "    palabras = entrada.split()\n",
    "    palabras_corregidas = [spell.correction(palabra) or palabra for palabra in palabras]  # Usar 'or' para manejar None\n",
    "    return ' '.join(palabras_corregidas)\n",
    "\n",
    "# Crear una lista de preguntas del corpus\n",
    "preguntas_corpus = [item['question'] for item in corpus['faq']]\n",
    "\n",
    "# Función para buscar la respuesta más relevante usando similitud semántica\n",
    "def buscar_respuesta_semantica(user_question):\n",
    "    \"\"\"\n",
    "    Encuentra la respuesta más relevante en el corpus usando similitud semántica.\n",
    "    \"\"\"\n",
    "    # Preprocesar la pregunta del usuario para mejorar la similitud\n",
    "    user_question = LemNormalize(user_question)\n",
    "    user_question = ' '.join(user_question)  # Convertir lista de palabras a texto\n",
    "\n",
    "    # Combinar la pregunta del usuario con las preguntas del corpus\n",
    "    preguntas = preguntas_corpus + [user_question]\n",
    "\n",
    "    # Vectorizar las preguntas\n",
    "    vectorizador = TfidfVectorizer()\n",
    "    vectores = vectorizador.fit_transform(preguntas)\n",
    "\n",
    "    # Calcular la similitud coseno entre la pregunta del usuario y las preguntas del corpus\n",
    "    similitudes = cosine_similarity(vectores[-1], vectores[:-1])\n",
    "\n",
    "    # Encontrar el índice de la pregunta más similar\n",
    "    indice_max = similitudes.argsort()[0][-1]\n",
    "\n",
    "    # Si la similitud es baja, devolver un mensaje predeterminado\n",
    "    if similitudes[0][indice_max] < 0.3:  # Ajustar el umbral de similitud\n",
    "        return \"Lo siento, no tengo una respuesta para esa pregunta. Por favor, intenta con otra consulta.\"\n",
    "\n",
    "    # Devolver la respuesta correspondiente\n",
    "    return corpus['faq'][indice_max]['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Preprocesamiento del texto y evaluación de la similitud entre el mensaje de usuario y las respuestas definidas en el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para determinar la similitud del texto insertado y el corpus\n",
    "def response(user_response):\n",
    "    robo_response = ''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=stopwords.words('spanish'))\n",
    "    caract_textos = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(caract_textos[-1], caract_textos)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    nivel_coincidencia = flat[-2]\n",
    "    if nivel_coincidencia == 0:\n",
    "        robo_response = \"Lo siento, no te he entendido. Si necesitas ayuda, escribe 'ayuda'.\"\n",
    "    else:\n",
    "        respuesta = sent_tokens[idx]\n",
    "        if len(respuesta) > 200:  # Limitar la longitud de la respuesta\n",
    "            respuesta = respuesta[:200] + '...'  # Agregar puntos suspensivos si es muy larga\n",
    "        robo_response = respuesta\n",
    "    sent_tokens.remove(user_response)\n",
    "    return robo_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Definición de funcionalidades de saludo y despedida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "saludo_inputs = (\"hola\", \"buenas\", \"saludos\", \"qué tal\", \"hey\", \"buenos días\", \"ayuda\")\n",
    "saludo_outputs = [\n",
    "    \"Hola, ¿cómo puedo ayudarte?\",\n",
    "    \"Hola, ¿en qué puedo asistirte?\",\n",
    "    \"Hola, dime cómo puedo ayudarte.\"\n",
    "]\n",
    "\n",
    "despedidas = [\n",
    "    \"Nos vemos, espero haberte ayudado.\",\n",
    "    \"Hasta pronto, ¡cuídate!\",\n",
    "    \"Chao, que tengas un buen día.\"\n",
    "]\n",
    "\n",
    "def saludos(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in saludo_inputs:\n",
    "            return random.choice(saludo_outputs)\n",
    "\n",
    "def despedida():\n",
    "    return random.choice(despedidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Bucle conversacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHATBOT: Mi nombre es CHATBOT. Contestaré a tus preguntas acerca del proyecto. Si necesitas ayuda, escribe 'ayuda'. Para salir, escribe 'salir'.\n",
      "CHATBOT: Hola, dime cómo puedo ayudarte.\n",
      "CHATBOT: Hola, dime cómo puedo ayudarte.\n",
      "CHATBOT: Lo siento, no tengo una respuesta para esa pregunta. Por favor, intenta con otra consulta.\n",
      "CHATBOT: Lo siento, no tengo una respuesta para esa pregunta. Por favor, intenta con otra consulta.\n",
      "CHATBOT: Predicción de niveles de exposición electromagnética en Colombia utilizando técnicas de Machine Learning.\n",
      "CHATBOT: Predicción de niveles de exposición electromagnética en Colombia utilizando técnicas de Machine Learning.\n",
      "CHATBOT: Lo siento, no tengo una respuesta para esa pregunta. Por favor, intenta con otra consulta.\n",
      "CHATBOT: Lo siento, no tengo una respuesta para esa pregunta. Por favor, intenta con otra consulta.\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print(\"CHATBOT: Mi nombre es CHATBOT. Contestaré a tus preguntas acerca del proyecto. Si necesitas ayuda, escribe 'ayuda'. Para salir, escribe 'salir'.\")\n",
    "while flag:\n",
    "    user_response = input().lower()\n",
    "    user_response = corregir_entrada(user_response)  # Corregir la entrada del usuario\n",
    "    if user_response != 'salir':\n",
    "        if user_response in ['gracias', 'muchas gracias']:\n",
    "            print(\"CHATBOT: No hay de qué.\")\n",
    "        elif user_response == 'ayuda':\n",
    "            print(\"CHATBOT: Puedes preguntarme sobre los participantes, objetivos, conclusiones, modelos, etc. Si quieres salir, escribe 'salir'.\")\n",
    "        elif saludos(user_response) is not None:\n",
    "            print(\"CHATBOT: \" + saludos(user_response))\n",
    "        else:\n",
    "            print(\"CHATBOT: \" + buscar_respuesta_semantica(user_response))\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"CHATBOT: \" + despedida())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
