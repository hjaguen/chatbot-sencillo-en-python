{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot informativo implementado al 100% en Python\n",
    "\n",
    "### Es un ejemplo sencillo de chatbot que implementa el corpus en un archivo '.txt' y que emplea las librerías nltk y scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El chatbot informa a los usuarios acerca de las normas de un crucero. Es un ejemplo básico, pero que bien sirve de ejemplo de uso de lematización y búsqueda de coincidencias entre las preguntas de usuario y las diferentes respuestas posibles mediante el modelo \"cosine_similarity\"\n",
    "\n",
    "#### Resumen técnico.\n",
    "\n",
    "##### 1.- En una variable de texto se almacena el corpus (diferentes respuestas posibles al usuario).\n",
    "##### 2.- Cuando el usuario plantea una pregunta, se agrega -temporalmente- al final de la lista de respuestas. A todo este contenido se le eliminan signos de puntuación, se tokeniza, lematiza y se extraen sus caracterísaticas -mediante TfidfVectorizer de sklearn-. A partir de ellas y empleando un modelo del tipo \"cosine_similarity\" se buscan las respuestas más coincidentes con la pregunta del usuario, se elige la que mayor grado de coincidentcia muestra y se responde con ella.\n",
    "##### 3.- Adicionalmente se ha incluido un pequeño módulo de saludo inicial, que aleatoriamente elige una respuesta entre varias posibles.\n",
    "\n",
    "\n",
    "#### Próximamente subiré un sistema similar pero del tipo \"voice bot\", empleando para ello librerías de reconocimiento y síntesis de voz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "#nltk.download('punkt') # Instalar módulo punkt si no está ya instalado (solo ejecutar la primera vez)\n",
    "#nltk.download('wordnet') # Instalar módulo wordnet si no está ya instalado (solo ejecutar la primera vez)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1 Carga del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el corpus estructurado\n",
    "with open('/home/mauricio/repos/source/chatbot/data.json', 'r') as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "# Inicializar la variable 'raw' con el contenido del corpus\n",
    "raw = \" \".join([item['question'] + \" \" + item['answer'] for item in corpus['faq']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Definición de funciones y variables de apoyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=raw.lower() # Convertimos todo el texto a minúsculas, para evitar deficiencias en la extracción de características\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(raw) # Convierte el corpus a una lista de sentencias\n",
    "word_tokens = nltk.word_tokenize(raw) # Convierte el corpus a una lista de palabras\n",
    "\n",
    "lemmer = nltk.stem.WordNetLemmatizer() # Instanciamos el lematizador, con el que convertir las palabras  a sus raíces contextuales\n",
    "\n",
    "#LemTokens es una función que lematiza todos los tokens que se le pasan como parámetro\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# remove_punct es un diccionario del tipo (0signo de puntuación', None), que se emplea en la función\n",
    "# LemNormalize para sustituir los signos de puntuación por \"nada\" es decir, eliminarlos.\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "# Dado un texto como parámetro, elimina los signos de puntuación, lo convierte a minúsculas,\n",
    "# lo tokeniza -por palabras- y finalmente lo lematiza\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "# Inicializar el corrector ortográfico\n",
    "spell = SpellChecker(language='es')\n",
    "\n",
    "def corregir_entrada(entrada):\n",
    "    \"\"\"\n",
    "    Corrige faltas ortográficas en una entrada de texto.\n",
    "    Si no se encuentra una corrección, se mantiene la palabra original.\n",
    "    \"\"\"\n",
    "    palabras = entrada.split()\n",
    "    palabras_corregidas = [spell.correction(palabra) or palabra for palabra in palabras]  # Usar 'or' para manejar None\n",
    "    return ' '.join(palabras_corregidas)\n",
    "\n",
    "# Diccionario de sinónimos y términos relacionados para expansión\n",
    "terminos_ampliados = {\n",
    "    # Términos relacionados con el proyecto\n",
    "    \"título\": [\"nombre\", \"denominación\", \"tema\", \"proyecto\"],\n",
    "    \"proyecto\": [\"estudio\", \"investigación\", \"trabajo\", \"iniciativa\"],\n",
    "    \"exposición\": [\"radiación\", \"emisión\", \"campos\"],\n",
    "    \"electromagnética\": [\"electromagnetismo\", \"electromagnético\", \"radiación\", \"EMF\"],\n",
    "    \"machine learning\": [\"ml\", \"aprendizaje automático\", \"aprendizaje de máquina\", \"ia\", \"inteligencia artificial\"],\n",
    "    \n",
    "    # Términos relacionados con objetivos\n",
    "    \"objetivos\": [\"metas\", \"propósitos\", \"fines\", \"finalidad\"],\n",
    "    \"general\": [\"principal\", \"primario\", \"central\"],\n",
    "    \"específicos\": [\"secundarios\", \"concretos\", \"particulares\"],\n",
    "    \n",
    "    # Términos relacionados con modelos\n",
    "    \"modelos\": [\"algoritmos\", \"técnicas\", \"métodos\", \"enfoques\"],\n",
    "    \"regresión\": [\"predicción\", \"estimación\"],\n",
    "    \"árboles\": [\"decision trees\", \"árbol de decisión\"],\n",
    "    \"random forest\": [\"bosque aleatorio\", \"rf\"],\n",
    "    \"xgboost\": [\"gradient boosting\", \"boosting\"],\n",
    "    \n",
    "    # Términos relacionados con datos\n",
    "    \"datos\": [\"información\", \"dataset\", \"conjunto de datos\", \"fuentes\"],\n",
    "    \"variables\": [\"características\", \"features\", \"atributos\", \"parámetros\"],\n",
    "    \n",
    "    # Términos relacionados con el problema\n",
    "    \"problema\": [\"desafío\", \"reto\", \"cuestión\", \"dificultad\"],\n",
    "    \"planteamiento\": [\"formulación\", \"definición\", \"descripción\"],\n",
    "    \n",
    "    # Términos relacionados con beneficios\n",
    "    \"beneficios\": [\"ventajas\", \"utilidad\", \"provecho\", \"aportes\"],\n",
    "    \"ventajas\": [\"beneficios\", \"fortalezas\", \"puntos fuertes\"],\n",
    "    \n",
    "    # Términos relacionados con conclusiones\n",
    "    \"conclusiones\": [\"resultados\", \"hallazgos\", \"descubrimientos\", \"inferencias\"]\n",
    "}\n",
    "\n",
    "def expandir_terminos(texto):\n",
    "    \"\"\"\n",
    "    Expande los términos clave en el texto con sinónimos y términos relacionados.\n",
    "    \"\"\"\n",
    "    palabras = texto.lower().split()\n",
    "    texto_expandido = texto.lower()\n",
    "    \n",
    "    # Buscar términos clave en el texto\n",
    "    for termino, expansiones in terminos_ampliados.items():\n",
    "        if termino in texto.lower():\n",
    "            # Añadir términos relacionados al texto expandido\n",
    "            terminos_adicionales = \" \".join(expansiones)\n",
    "            texto_expandido += f\" {terminos_adicionales}\"\n",
    "    \n",
    "    return texto_expandido\n",
    "\n",
    "# Mejorar la función LemNormalize para usar la expansión de términos\n",
    "def LemNormalize_mejorado(text):\n",
    "    \"\"\"\n",
    "    Versión mejorada de LemNormalize que también expande términos clave.\n",
    "    \"\"\"\n",
    "    # Expandir términos clave\n",
    "    texto_expandido = expandir_terminos(text)\n",
    "    \n",
    "    # Aplicar la normalización estándar\n",
    "    return LemTokens(nltk.word_tokenize(texto_expandido.lower().translate(remove_punct_dict)))\n",
    "\n",
    "# Crear una lista de preguntas del corpus\n",
    "preguntas_corpus = [item['question'] for item in corpus['faq']]\n",
    "\n",
    "# Función mejorada para buscar la respuesta más relevante usando similitud semántica\n",
    "\n",
    "def buscar_respuesta_semantica(user_question, umbral_base=0.28, modo=\"adaptativo\"):\n",
    "    \"\"\"\n",
    "    Encuentra la respuesta más relevante en el corpus usando similitud semántica mejorada.\n",
    "    \n",
    "    Parámetros:\n",
    "    - user_question: Pregunta del usuario\n",
    "    - umbral_base: Umbral base para considerar una respuesta como relevante\n",
    "    - modo: Tipo de umbral a utilizar ('fijo', 'adaptativo', 'diferencial', 'hibrido')\n",
    "    \"\"\"\n",
    "    # Preprocesar la pregunta del usuario con expansión de términos\n",
    "    user_question_expandida = expandir_terminos(user_question)\n",
    "    user_tokens = LemNormalize_mejorado(user_question_expandida)\n",
    "    user_question_procesada = ' '.join(user_tokens)  # Convertir lista de palabras a texto\n",
    "    \n",
    "    # Preprocesar las preguntas del corpus si no se ha hecho aún\n",
    "    preguntas_procesadas = []\n",
    "    for pregunta in preguntas_corpus:\n",
    "        pregunta_expandida = expandir_terminos(pregunta)\n",
    "        tokens = LemNormalize_mejorado(pregunta_expandida)\n",
    "        preguntas_procesadas.append(' '.join(tokens))\n",
    "        \n",
    "    # Combinar la pregunta del usuario con las preguntas procesadas del corpus\n",
    "    todas_preguntas = preguntas_procesadas + [user_question_procesada]\n",
    "    \n",
    "    # Vectorizar las preguntas con parámetros mejorados\n",
    "    vectorizador = TfidfVectorizer(\n",
    "        min_df=1,                 # Incluir términos que aparecen al menos en 1 documento\n",
    "        max_df=0.95,              # Excluir términos que aparecen en más del 95% de documentos\n",
    "        ngram_range=(1, 3),       # Considerar hasta trigramas para capturar frases más largas\n",
    "        sublinear_tf=True,        # Aplica logaritmo para reducir el impacto de términos frecuentes\n",
    "        use_idf=True,             # Usar IDF para dar más peso a términos discriminativos\n",
    "        smooth_idf=True           # Evitar división por cero\n",
    "    )\n",
    "    vectores = vectorizador.fit_transform(todas_preguntas)\n",
    "    \n",
    "    # Calcular la similitud coseno entre la pregunta del usuario y las preguntas del corpus\n",
    "    similitudes = cosine_similarity(vectores[-1], vectores[:-1])[0]\n",
    "    \n",
    "    # Encontrar el índice de la pregunta más similar y la segunda más similar\n",
    "    similitudes_ordenadas = np.sort(similitudes)[::-1]\n",
    "    indice_max = similitudes.argmax()\n",
    "    max_similitud = similitudes[indice_max]\n",
    "    \n",
    "    # Si tenemos al menos dos preguntas para comparar\n",
    "    segunda_max = similitudes_ordenadas[1] if len(similitudes_ordenadas) > 1 else 0\n",
    "    diferencia = max_similitud - segunda_max\n",
    "    \n",
    "    # Aplicar diferentes estrategias de umbral según el modo\n",
    "    if modo == \"fijo\":\n",
    "        # Umbral fijo simple\n",
    "        if max_similitud < umbral_base:\n",
    "            return \"Lo siento, no tengo una respuesta para esa pregunta. Por favor, intenta con otra consulta.\"\n",
    "    \n",
    "    elif modo == \"adaptativo\":\n",
    "        # Umbral adaptativo basado en la distribución de similitudes\n",
    "        media_similitud = similitudes.mean()\n",
    "        desv_similitud = similitudes.std()\n",
    "        # Si la mejor similitud está cerca de la media, podría ser ruido\n",
    "        umbral_adaptativo = min(umbral_base, media_similitud + desv_similitud * 0.8)\n",
    "        \n",
    "        if max_similitud < umbral_adaptativo:\n",
    "            return \"Lo siento, no tengo una respuesta para esa pregunta. Por favor, intenta con otra consulta.\"\n",
    "    \n",
    "    elif modo == \"diferencial\":\n",
    "        # Umbral basado en la diferencia entre la mejor y segunda mejor coincidencia\n",
    "        # Si hay una gran diferencia, tenemos más confianza\n",
    "        if len(similitudes_ordenadas) > 1:\n",
    "            # Reducimos el umbral si hay una gran diferencia (alta confianza)\n",
    "            umbral_diferencial = umbral_base - min(0.18, diferencia * 1.8)\n",
    "        else:\n",
    "            umbral_diferencial = umbral_base\n",
    "            \n",
    "        if max_similitud < umbral_diferencial:\n",
    "            return \"Lo siento, no tengo una respuesta para esa pregunta. Por favor, intenta con otra consulta.\"\n",
    "    \n",
    "    elif modo == \"hibrido\":\n",
    "        # Combinación de adaptativo y diferencial\n",
    "        media_similitud = similitudes.mean()\n",
    "        desv_similitud = similitudes.std()\n",
    "        \n",
    "        # Componente adaptativo\n",
    "        umbral_adaptativo = min(umbral_base, media_similitud + desv_similitud)\n",
    "        \n",
    "        # Componente diferencial\n",
    "        if len(similitudes_ordenadas) > 1:\n",
    "            umbral_diferencial = umbral_base - min(0.15, diferencia * 1.5)\n",
    "        else:\n",
    "            umbral_diferencial = umbral_base\n",
    "        \n",
    "        # Tomar el mínimo de ambos (más permisivo)\n",
    "        umbral_hibrido = min(umbral_adaptativo, umbral_diferencial)\n",
    "        \n",
    "        if max_similitud < umbral_hibrido:\n",
    "            return \"Lo siento, no tengo una respuesta para esa pregunta. Por favor, intenta con otra consulta.\"\n",
    "    \n",
    "    # Devolver la respuesta correspondiente con un nivel de confianza\n",
    "    respuesta = corpus['faq'][indice_max]['answer']\n",
    "    \n",
    "    # Incluir nivel de confianza solo si es relevante\n",
    "    if max_similitud > 0.8:\n",
    "        return respuesta  # Alta confianza, no mostramos el valor\n",
    "    elif max_similitud > 0.6:\n",
    "        return respuesta  # Confianza media, no mostramos el valor\n",
    "    else:\n",
    "        # Baja confianza, podríamos mostrar el valor o no\n",
    "        return respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación de precisión del chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando con umbral=0.25, modo=fijo\n",
      "Precisión del chatbot: 73.33%\n",
      "Aciertos: 22/30\n",
      "\n",
      "Detalles de algunas predicciones incorrectas:\n",
      "Pregunta: nombre del proyecto de exposición electromagnética\n",
      "Esperado: Predicción de niveles de exposición electromagnéti...\n",
      "Generado: Es la exposición a campos electromagnéticos genera...\n",
      "--------------------------------------------------\n",
      "Pregunta: modelos utilizados en machine learning\n",
      "Esperado: Se usaron modelos como Regresión Lineal, Árboles d...\n",
      "Generado: Se utilizaron métricas como el Error Cuadrático Me...\n",
      "--------------------------------------------------\n",
      "Pregunta: explicación del problema principal\n",
      "Esperado: El problema radica en la falta de un modelo predic...\n",
      "Generado: El problema radica en la falta de un modelo predic...\n",
      "--------------------------------------------------\n",
      "Pregunta: resultados finales del proyecto\n",
      "Esperado: Se demostró que es posible predecir la fluctuación...\n",
      "Generado: ¿Es posible predecir la fluctuación de los niveles...\n",
      "--------------------------------------------------\n",
      "Pregunta: que hace el proyecto\n",
      "Esperado: El objetivo general es ilustrar las primeras fases...\n",
      "Generado: Participaron Andres Mauricio Ardila, Claudia Ines ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando con umbral=0.28, modo=adaptativo\n",
      "Precisión del chatbot: 83.33%\n",
      "Aciertos: 25/30\n",
      "\n",
      "Detalles de algunas predicciones incorrectas:\n",
      "Pregunta: nombre del proyecto de exposición electromagnética\n",
      "Esperado: Predicción de niveles de exposición electromagnéti...\n",
      "Generado: Es la exposición a campos electromagnéticos genera...\n",
      "--------------------------------------------------\n",
      "Pregunta: modelos utilizados en machine learning\n",
      "Esperado: Se usaron modelos como Regresión Lineal, Árboles d...\n",
      "Generado: Se utilizaron métricas como el Error Cuadrático Me...\n",
      "--------------------------------------------------\n",
      "Pregunta: explicación del problema principal\n",
      "Esperado: El problema radica en la falta de un modelo predic...\n",
      "Generado: El problema radica en la falta de un modelo predic...\n",
      "--------------------------------------------------\n",
      "Pregunta: resultados finales del proyecto\n",
      "Esperado: Se demostró que es posible predecir la fluctuación...\n",
      "Generado: ¿Es posible predecir la fluctuación de los niveles...\n",
      "--------------------------------------------------\n",
      "Pregunta: que hace el proyecto\n",
      "Esperado: El objetivo general es ilustrar las primeras fases...\n",
      "Generado: Participaron Andres Mauricio Ardila, Claudia Ines ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando con umbral=0.3, modo=adaptativo\n",
      "Precisión del chatbot: 83.33%\n",
      "Aciertos: 25/30\n",
      "\n",
      "Detalles de algunas predicciones incorrectas:\n",
      "Pregunta: nombre del proyecto de exposición electromagnética\n",
      "Esperado: Predicción de niveles de exposición electromagnéti...\n",
      "Generado: Es la exposición a campos electromagnéticos genera...\n",
      "--------------------------------------------------\n",
      "Pregunta: modelos utilizados en machine learning\n",
      "Esperado: Se usaron modelos como Regresión Lineal, Árboles d...\n",
      "Generado: Se utilizaron métricas como el Error Cuadrático Me...\n",
      "--------------------------------------------------\n",
      "Pregunta: explicación del problema principal\n",
      "Esperado: El problema radica en la falta de un modelo predic...\n",
      "Generado: El problema radica en la falta de un modelo predic...\n",
      "--------------------------------------------------\n",
      "Pregunta: resultados finales del proyecto\n",
      "Esperado: Se demostró que es posible predecir la fluctuación...\n",
      "Generado: ¿Es posible predecir la fluctuación de los niveles...\n",
      "--------------------------------------------------\n",
      "Pregunta: que hace el proyecto\n",
      "Esperado: El objetivo general es ilustrar las primeras fases...\n",
      "Generado: Participaron Andres Mauricio Ardila, Claudia Ines ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando con umbral=0.35, modo=diferencial\n",
      "Precisión del chatbot: 73.33%\n",
      "Aciertos: 22/30\n",
      "\n",
      "Detalles de algunas predicciones incorrectas:\n",
      "Pregunta: nombre del proyecto de exposición electromagnética\n",
      "Esperado: Predicción de niveles de exposición electromagnéti...\n",
      "Generado: Es la exposición a campos electromagnéticos genera...\n",
      "--------------------------------------------------\n",
      "Pregunta: modelos utilizados en machine learning\n",
      "Esperado: Se usaron modelos como Regresión Lineal, Árboles d...\n",
      "Generado: Se utilizaron métricas como el Error Cuadrático Me...\n",
      "--------------------------------------------------\n",
      "Pregunta: explicación del problema principal\n",
      "Esperado: El problema radica en la falta de un modelo predic...\n",
      "Generado: El problema radica en la falta de un modelo predic...\n",
      "--------------------------------------------------\n",
      "Pregunta: resultados finales del proyecto\n",
      "Esperado: Se demostró que es posible predecir la fluctuación...\n",
      "Generado: ¿Es posible predecir la fluctuación de los niveles...\n",
      "--------------------------------------------------\n",
      "Pregunta: que hace el proyecto\n",
      "Esperado: El objetivo general es ilustrar las primeras fases...\n",
      "Generado: Participaron Andres Mauricio Ardila, Claudia Ines ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando con umbral=0.32, modo=diferencial\n",
      "Precisión del chatbot: 73.33%\n",
      "Aciertos: 22/30\n",
      "\n",
      "Detalles de algunas predicciones incorrectas:\n",
      "Pregunta: nombre del proyecto de exposición electromagnética\n",
      "Esperado: Predicción de niveles de exposición electromagnéti...\n",
      "Generado: Es la exposición a campos electromagnéticos genera...\n",
      "--------------------------------------------------\n",
      "Pregunta: modelos utilizados en machine learning\n",
      "Esperado: Se usaron modelos como Regresión Lineal, Árboles d...\n",
      "Generado: Se utilizaron métricas como el Error Cuadrático Me...\n",
      "--------------------------------------------------\n",
      "Pregunta: explicación del problema principal\n",
      "Esperado: El problema radica en la falta de un modelo predic...\n",
      "Generado: El problema radica en la falta de un modelo predic...\n",
      "--------------------------------------------------\n",
      "Pregunta: resultados finales del proyecto\n",
      "Esperado: Se demostró que es posible predecir la fluctuación...\n",
      "Generado: ¿Es posible predecir la fluctuación de los niveles...\n",
      "--------------------------------------------------\n",
      "Pregunta: que hace el proyecto\n",
      "Esperado: El objetivo general es ilustrar las primeras fases...\n",
      "Generado: Participaron Andres Mauricio Ardila, Claudia Ines ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando con umbral=0.28, modo=hibrido\n",
      "Precisión del chatbot: 83.33%\n",
      "Aciertos: 25/30\n",
      "\n",
      "Detalles de algunas predicciones incorrectas:\n",
      "Pregunta: nombre del proyecto de exposición electromagnética\n",
      "Esperado: Predicción de niveles de exposición electromagnéti...\n",
      "Generado: Es la exposición a campos electromagnéticos genera...\n",
      "--------------------------------------------------\n",
      "Pregunta: modelos utilizados en machine learning\n",
      "Esperado: Se usaron modelos como Regresión Lineal, Árboles d...\n",
      "Generado: Se utilizaron métricas como el Error Cuadrático Me...\n",
      "--------------------------------------------------\n",
      "Pregunta: explicación del problema principal\n",
      "Esperado: El problema radica en la falta de un modelo predic...\n",
      "Generado: El problema radica en la falta de un modelo predic...\n",
      "--------------------------------------------------\n",
      "Pregunta: resultados finales del proyecto\n",
      "Esperado: Se demostró que es posible predecir la fluctuación...\n",
      "Generado: ¿Es posible predecir la fluctuación de los niveles...\n",
      "--------------------------------------------------\n",
      "Pregunta: que hace el proyecto\n",
      "Esperado: El objetivo general es ilustrar las primeras fases...\n",
      "Generado: Participaron Andres Mauricio Ardila, Claudia Ines ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Mejor configuración: adaptativo_0.28 con precisión: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Actualizar la función evaluar_precision_optimizada\n",
    "\n",
    "def evaluar_precision_optimizada():\n",
    "    \"\"\"\n",
    "    Evalúa la precisión del chatbot con distintas configuraciones para encontrar la óptima.\n",
    "    \"\"\"\n",
    "    # Configuraciones a probar (ampliadas)\n",
    "    configuraciones = [\n",
    "        {\"umbral\": 0.25, \"modo\": \"fijo\"},\n",
    "        {\"umbral\": 0.28, \"modo\": \"adaptativo\"},\n",
    "        {\"umbral\": 0.3, \"modo\": \"adaptativo\"},\n",
    "        {\"umbral\": 0.35, \"modo\": \"diferencial\"},\n",
    "        {\"umbral\": 0.32, \"modo\": \"diferencial\"},\n",
    "        {\"umbral\": 0.28, \"modo\": \"hibrido\"}  # Nuevo modo híbrido\n",
    "    ]\n",
    "    \n",
    "    resultados_config = {}\n",
    "    \n",
    "    # Crear datos de prueba\n",
    "    datos_prueba = []\n",
    "    \n",
    "    # Usar preguntas originales del corpus\n",
    "    for item in corpus['faq'][:15]:  # Usar más preguntas para una evaluación más completa\n",
    "        datos_prueba.append({\n",
    "            \"pregunta\": item['question'], \n",
    "            \"respuesta_esperada\": item['answer']\n",
    "        })\n",
    "    \n",
    "    # Incluir las variaciones como antes\n",
    "    variaciones_preguntas = [\n",
    "        {\"pregunta\": \"¿Podrías decirme cuál es el título del proyecto?\", \n",
    "         \"respuesta_esperada\": corpus['faq'][0]['answer']},\n",
    "        {\"pregunta\": \"título del proyecto\", \n",
    "         \"respuesta_esperada\": corpus['faq'][0]['answer']},\n",
    "        {\"pregunta\": \"nombre del proyecto de exposición electromagnética\", \n",
    "         \"respuesta_esperada\": corpus['faq'][0]['answer']},\n",
    "        {\"pregunta\": \"objetivos principales\", \n",
    "         \"respuesta_esperada\": corpus['faq'][1]['answer']},\n",
    "        {\"pregunta\": \"¿Me podrías explicar qué es la exposición electromagnética?\", \n",
    "         \"respuesta_esperada\": corpus['faq'][2]['answer']},\n",
    "        {\"pregunta\": \"modelos utilizados en machine learning\", \n",
    "         \"respuesta_esperada\": corpus['faq'][3]['answer']},\n",
    "        {\"pregunta\": \"fuente de los datos del proyecto\", \n",
    "         \"respuesta_esperada\": corpus['faq'][4]['answer']},\n",
    "        {\"pregunta\": \"explicación del problema principal\", \n",
    "         \"respuesta_esperada\": corpus['faq'][5]['answer']},\n",
    "        {\"pregunta\": \"ventajas de este estudio\", \n",
    "         \"respuesta_esperada\": corpus['faq'][6]['answer']},\n",
    "        {\"pregunta\": \"resultados finales del proyecto\", \n",
    "         \"respuesta_esperada\": corpus['faq'][7]['answer']}\n",
    "    ]\n",
    "    \n",
    "    # Añadir más variaciones más desafiantes\n",
    "    variaciones_adicionales = [\n",
    "        {\"pregunta\": \"dime sobre el título\", \n",
    "         \"respuesta_esperada\": corpus['faq'][0]['answer']},\n",
    "        {\"pregunta\": \"que hace el proyecto\", \n",
    "         \"respuesta_esperada\": corpus['faq'][1]['answer']},\n",
    "        {\"pregunta\": \"campos electromagnéticos explicación\", \n",
    "         \"respuesta_esperada\": corpus['faq'][2]['answer']},\n",
    "        {\"pregunta\": \"técnicas de ML usadas\", \n",
    "         \"respuesta_esperada\": corpus['faq'][3]['answer']},\n",
    "        {\"pregunta\": \"de dónde sacaron la información\", \n",
    "         \"respuesta_esperada\": corpus['faq'][4]['answer']}\n",
    "    ]\n",
    "    \n",
    "    # Añadir todas las variaciones\n",
    "    datos_prueba.extend(variaciones_preguntas)\n",
    "    datos_prueba.extend(variaciones_adicionales)\n",
    "    \n",
    "    # Para cada configuración, evaluar la precisión\n",
    "    for config in configuraciones:\n",
    "        umbral = config[\"umbral\"]\n",
    "        modo = config[\"modo\"]\n",
    "        \n",
    "        print(f\"\\nEvaluando con umbral={umbral}, modo={modo}\")\n",
    "        \n",
    "        aciertos = 0\n",
    "        resultados = []\n",
    "        \n",
    "        for caso in datos_prueba:\n",
    "            # Usar la configuración específica\n",
    "            respuesta_generada = buscar_respuesta_semantica(\n",
    "                caso['pregunta'], \n",
    "                umbral_base=umbral,\n",
    "                modo=modo\n",
    "            )\n",
    "            \n",
    "            # Comparar respuestas ignorando el nivel de confianza (si está presente)\n",
    "            respuesta_generada_limpia = respuesta_generada.split(\" (Confianza:\")[0]\n",
    "            respuesta_esperada_limpia = caso['respuesta_esperada'].split(\" (Confianza:\")[0]\n",
    "            \n",
    "            es_correcto = respuesta_generada_limpia == respuesta_esperada_limpia\n",
    "            \n",
    "            if es_correcto:\n",
    "                aciertos += 1\n",
    "                \n",
    "            resultados.append({\n",
    "                \"pregunta\": caso['pregunta'],\n",
    "                \"respuesta_esperada\": caso['respuesta_esperada'],\n",
    "                \"respuesta_generada\": respuesta_generada,\n",
    "                \"correcto\": es_correcto\n",
    "            })\n",
    "        \n",
    "        precision = aciertos / len(datos_prueba)\n",
    "        resultados_config[f\"{modo}_{umbral}\"] = precision\n",
    "        \n",
    "        # Mostrar resultados\n",
    "        print(f\"Precisión del chatbot: {precision * 100:.2f}%\")\n",
    "        print(f\"Aciertos: {aciertos}/{len(datos_prueba)}\")\n",
    "        \n",
    "        # Mostrar errores (limitados para evitar sobrecarga)\n",
    "        print(\"\\nDetalles de algunas predicciones incorrectas:\")\n",
    "        errores_mostrados = 0\n",
    "        for resultado in resultados:\n",
    "            if not resultado[\"correcto\"] and errores_mostrados < 5:  # Limitar a 5 errores mostrados\n",
    "                print(f\"Pregunta: {resultado['pregunta']}\")\n",
    "                print(f\"Esperado: {resultado['respuesta_esperada'][:50]}...\")\n",
    "                print(f\"Generado: {resultado['respuesta_generada'][:50]}...\")\n",
    "                print(\"-\" * 50)\n",
    "                errores_mostrados += 1\n",
    "    \n",
    "    # Encontrar la mejor configuración\n",
    "    mejor_config = max(resultados_config, key=resultados_config.get)\n",
    "    print(f\"\\nMejor configuración: {mejor_config} con precisión: {resultados_config[mejor_config] * 100:.2f}%\")\n",
    "    \n",
    "    return resultados_config, mejor_config\n",
    "\n",
    "# Ejecutar la evaluación optimizada\n",
    "resultados_optimizados, mejor_configuracion = evaluar_precision_optimizada()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Preprocesamiento del texto y evaluación de la similitud entre el mensaje de usuario y las respuestas definidas en el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función mejorada para determinar la similitud del texto insertado y el corpus\n",
    "def response(user_response):\n",
    "    robo_response = ''\n",
    "    sent_tokens.append(user_response)\n",
    "    \n",
    "    # Utilizar una vectorización más avanzada\n",
    "    TfidfVec = TfidfVectorizer(\n",
    "        tokenizer=LemNormalize, \n",
    "        stop_words=stopwords.words('spanish'),\n",
    "        min_df=1,\n",
    "        max_df=0.9,\n",
    "        ngram_range=(1, 2),\n",
    "        sublinear_tf=True\n",
    "    )\n",
    "    \n",
    "    caract_textos = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(caract_textos[-1], caract_textos)\n",
    "    \n",
    "    # Obtenemos los índices ordenados por similitud (de menor a mayor)\n",
    "    indices_ordenados = vals.argsort()[0]\n",
    "    \n",
    "    # Tomamos los dos índices más altos (el último y el penúltimo)\n",
    "    idx_mejor = indices_ordenados[-2]  # -2 porque el último es la propia consulta\n",
    "    idx_segundo_mejor = indices_ordenados[-3] if len(indices_ordenados) > 2 else indices_ordenados[-2]\n",
    "    \n",
    "    # Aplanamos el array para análisis\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    \n",
    "    # Calculamos la diferencia entre las dos mejores coincidencias\n",
    "    mejor_coincidencia = flat[-2]\n",
    "    segunda_mejor = flat[-3] if len(flat) > 2 else 0\n",
    "    diferencia = mejor_coincidencia - segunda_mejor\n",
    "    \n",
    "    # Aplicamos un umbral adaptativo basado en la diferencia\n",
    "    umbral_adaptativo = 0.15 - min(0.1, diferencia * 0.5)\n",
    "    \n",
    "    if mejor_coincidencia < umbral_adaptativo:\n",
    "        robo_response = \"Lo siento, no te he entendido bien. ¿Podrías reformular tu pregunta? Si necesitas ayuda, escribe 'ayuda'.\"\n",
    "    else:\n",
    "        respuesta = sent_tokens[idx_mejor]\n",
    "        \n",
    "        # Si hay una gran diferencia entre la mejor y segunda mejor coincidencia,\n",
    "        # tenemos más confianza en nuestra respuesta\n",
    "        if diferencia > 0.2:\n",
    "            # Alta confianza - usamos la respuesta tal cual\n",
    "            if len(respuesta) > 200:\n",
    "                respuesta = respuesta[:200] + '...'\n",
    "        else:\n",
    "            # Baja diferencia - posible ambigüedad\n",
    "            # Intentamos una respuesta híbrida o más conservadora\n",
    "            if len(respuesta) > 150:\n",
    "                respuesta = respuesta[:150] + '...'\n",
    "            \n",
    "        robo_response = respuesta\n",
    "    \n",
    "    sent_tokens.remove(user_response)\n",
    "    return robo_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Definición de funcionalidades de saludo y despedida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "saludo_inputs = (\"hola\", \"buenas\", \"saludos\", \"qué tal\", \"hey\", \"buenos días\", \"ayuda\")\n",
    "saludo_outputs = [\n",
    "    \"Hola, ¿cómo puedo ayudarte?\",\n",
    "    \"Hola, ¿en qué puedo asistirte?\",\n",
    "    \"Hola, dime cómo puedo ayudarte.\"\n",
    "]\n",
    "\n",
    "despedidas = [\n",
    "    \"Nos vemos, espero haberte ayudado.\",\n",
    "    \"Hasta pronto, ¡cuídate!\",\n",
    "    \"Chao, que tengas un buen día.\"\n",
    "]\n",
    "\n",
    "def saludos(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in saludo_inputs:\n",
    "            return random.choice(saludo_outputs)\n",
    "\n",
    "def despedida():\n",
    "    return random.choice(despedidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Bucle conversacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHATBOT: Mi nombre es CHATBOT. Contestaré a tus preguntas acerca del proyecto. Si necesitas ayuda, escribe 'ayuda'. Para salir, escribe 'salir'.\n",
      "CHATBOT: Usando configuración optimizada: modo=adaptativo, umbral=0.28\n",
      "CHATBOT: Hola, dime cómo puedo ayudarte.\n",
      "CHATBOT: Participaron Andres Mauricio Ardila, Claudia Ines Giraldo, Marisela Lotero Zuluaga y como ejecutor técnico, la Ing. Darly Mildred Delgado.\n",
      "CHATBOT: Predicción de niveles de exposición electromagnética en Colombia utilizando técnicas de Machine Learning.\n",
      "CHATBOT: Predicción de niveles de exposición electromagnética en Colombia utilizando técnicas de Machine Learning.\n",
      "CHATBOT: Predicción de niveles de exposición electromagnética en Colombia utilizando técnicas de Machine Learning.\n",
      "CHATBOT: Predicción de niveles de exposición electromagnética en Colombia utilizando técnicas de Machine Learning.\n",
      "CHATBOT: Chao, que tengas un buen día.\n"
     ]
    }
   ],
   "source": [
    "# Reemplazar la parte final del bucle conversacional\n",
    "\n",
    "flag = True\n",
    "print(\"CHATBOT: Mi nombre es CHATBOT. Contestaré a tus preguntas acerca del proyecto. Si necesitas ayuda, escribe 'ayuda'. Para salir, escribe 'salir'.\")\n",
    "\n",
    "# Extraer la mejor configuración de la evaluación\n",
    "mejor_config_partes = mejor_configuracion.split('_')\n",
    "mejor_modo = mejor_config_partes[0]\n",
    "mejor_umbral = float(mejor_config_partes[1])\n",
    "\n",
    "print(f\"CHATBOT: Usando configuración optimizada: modo={mejor_modo}, umbral={mejor_umbral}\")\n",
    "\n",
    "while flag:\n",
    "    user_response = input().lower()\n",
    "    user_response = corregir_entrada(user_response)  # Corregir la entrada del usuario\n",
    "    \n",
    "    if user_response != 'salir':\n",
    "        if user_response in ['gracias', 'muchas gracias']:\n",
    "            print(\"CHATBOT: No hay de qué.\")\n",
    "        elif user_response == 'ayuda':\n",
    "            print(\"CHATBOT: Puedes preguntarme sobre los participantes, objetivos, conclusiones, modelos, etc. Si quieres salir, escribe 'salir'.\")\n",
    "        elif saludos(user_response) is not None:\n",
    "            print(\"CHATBOT: \" + saludos(user_response))\n",
    "        else:\n",
    "            # Usar la configuración optimizada\n",
    "            respuesta = buscar_respuesta_semantica(\n",
    "                user_response, \n",
    "                umbral_base=mejor_umbral,\n",
    "                modo=mejor_modo\n",
    "            )\n",
    "            print(\"CHATBOT: \" + respuesta)\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"CHATBOT: \" + despedida())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
